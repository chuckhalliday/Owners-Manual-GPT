{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42dec9d",
   "metadata": {},
   "source": [
    "# PDF Manual Reader\n",
    "This is a simple chatbot which can look up a give pdf and answer your questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f74ec2",
   "metadata": {},
   "source": [
    "### Download and install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 langchain openai python-dotenv\n",
    "!pip install typing-extensions --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fc9bf",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b1479",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader # for extracting text from pdf\n",
    "from langchain.text_splitter import CharacterTextSplitter # for splitting text in smaller snippets\n",
    "import os # for reading environment variables\n",
    "from dotenv import load_dotenv # for loading environment variables\n",
    "from openai import OpenAI # openai api\n",
    "import json # for storing snippets and embeddings in json\n",
    "from numpy import dot # for matching user questions with snippets.\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c56818",
   "metadata": {},
   "source": [
    "### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ffd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACTED_TEXT_FILE_PATH = \"pdf.txt\" # text extracted from pdf\n",
    "EXTRACTED_JSON_PATH = \"extracted.json\" # snippets and embeddings\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY') # add your openai key in a .env file\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\" # embedding model used\n",
    "GPT_MODEL = \"gpt-3.5-turbo\" # gpt model used. alternatively you can use gpt-4 or other models.\n",
    "CHUNK_SIZE = 1000 # chunk size of snippets\n",
    "CHUNK_OVERLAP = 200 # check size to create overlap between snippets\n",
    "CONFIDENCE_SCORE = 0.75 # for filtering search results. [0,1] prefered: 0.75 or greater"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c47ddd",
   "metadata": {},
   "source": [
    "### Extract text from pdf\n",
    "Then save in - `pdf_text.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path: str):\n",
    "    \n",
    "    reader = PdfReader(file_path)\n",
    "\n",
    "    number_of_pages = len(reader.pages)\n",
    "\n",
    "    pdf_text = \"\"\n",
    "\n",
    "    for i in range(number_of_pages):\n",
    "\n",
    "        page = reader.pages[i]\n",
    "\n",
    "        pdf_text += page.extract_text()\n",
    "        \n",
    "        # Add a newline after each page's text for readability\n",
    "        pdf_text += \"\\n\"\n",
    "    \n",
    "    # Specify the file path for the new text file\n",
    "    file_path = EXTRACTED_TEXT_FILE_PATH\n",
    "\n",
    "    # Write the content to the text file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c978bb82",
   "metadata": {},
   "source": [
    "### Turn text into embeddings\n",
    "Allows the computer to perform mathematical operations and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(file_path: str):\n",
    "    \n",
    "    snippets = []\n",
    "    # Initialize a CharacterTextSplitter with specified settings\n",
    "    text_splitter = CharacterTextSplitter(separator=\"\\n\",\n",
    "                                         chunk_size=CHUNK_SIZE,\n",
    "                                         chunk_overlap=CHUNK_OVERLAP,\n",
    "                                         length_function=len)\n",
    "\n",
    "    # Read the content of the file specified by file_path\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            file_text = file.read()\n",
    "\n",
    "    # Split the text into snippets using the specified settings\n",
    "    snippets = text_splitter.split_text(file_text)\n",
    "\n",
    "    \n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # Request embeddings for the snippets using the specified model\n",
    "    response = client.embeddings.create(input=snippets,model=EMBEDDING_MODEL)\n",
    "    \n",
    "    # Extract embeddings from the API response\n",
    "    embedding_list = [response_object.embedding for response_object in response.data]\n",
    "\n",
    "    # Create a JSON object containing embeddings and snippets\n",
    "    embedding_json = {\n",
    "        'embeddings': embedding_list,\n",
    "        'snippets': snippets\n",
    "    }\n",
    "    \n",
    "    # Convert the JSON object to a formatted JSON string\n",
    "    json_object = json.dumps(embedding_json, indent=4)\n",
    "\n",
    "    # Write the JSON string to a file specified by EXTRACTED_JSON_PATH\n",
    "    with open(EXTRACTED_JSON_PATH, 'w', encoding=\"utf-8\") as file:\n",
    "        file.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c821fc9f",
   "metadata": {},
   "source": [
    "### Read Embedding JSON file\n",
    "Reads `extracted.json` and prepared embedding for the advisor bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35e61f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_embeddings():\n",
    "    \n",
    "    # Open the JSON file containing embeddings and snippets\n",
    "    with open(EXTRACTED_JSON_PATH,'r') as file:\n",
    "        # Load the JSON data into a Python dictionary\n",
    "        embedding_json = json.load(file)\n",
    "        \n",
    "    # Return the embeddings and snippets from the loaded JSON\n",
    "    return embedding_json['embeddings'], embedding_json['snippets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4dcbb1",
   "metadata": {},
   "source": [
    "### Create Embedding from User's Question\n",
    "Output of this function is used to find the right embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_question_embedding_creator(question):\n",
    "    \n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # Request embedding for the provided question using the specified model\n",
    "    response = client.embeddings.create(input=question,model=EMBEDDING_MODEL)\n",
    "    \n",
    "    # Extract and return the embedding from the API response\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d016c0f",
   "metadata": {},
   "source": [
    "### Answer user's question\n",
    "The main event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_users_question(user_question):\n",
    "    \n",
    "    try:\n",
    "        # Create an embedding for the user's question\n",
    "        user_question_embedding = user_question_embedding_creator(user_question)\n",
    "    except Exception as e:\n",
    "        # Handle any exception that occurred while using Embedding API.\n",
    "        return f\"An error occurred while creating embedding: {str(e)}\"\n",
    "        \n",
    "    \n",
    "    # Calculate cosine similarities between the user's question embedding and the document embeddings\n",
    "    cosine_similarities = []\n",
    "    for embedding in embeddings:\n",
    "        cosine_similarities.append(dot(user_question_embedding,embedding))\n",
    "\n",
    "    # Pair snippets with their respective cosine similarities and sort them by similarity\n",
    "    scored_snippets = zip(snippets, cosine_similarities)\n",
    "    sorted_snippets = sorted(scored_snippets, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Filter snippets based on a confidence score and select the top 5 results\n",
    "    formatted_top_results = [snipps for snipps, _score in sorted_snippets if _score > CONFIDENCE_SCORE]\n",
    "    if len(formatted_top_results) > 5:\n",
    "        formatted_top_results = formatted_top_results[:5]\n",
    "        \n",
    "    # Create the chatbot system using pdf_description provided by the user.\n",
    "    chatbot_system = f\"\"\"You are provided with SEARCH RESULTS from a pdf. You need to generate answer to the user's question based on the given SEARCH RESULTS. SEARCH RESULTS as a python list. SEARCH RESULTS and USER's QUESTION are delimited by ``` \\n If there is no information available, or question is irrelevent respond with - \"Sorry! I can't help you.\" \"\"\"\n",
    "    \n",
    "    # Create the prompt using results and user's question.\n",
    "    prompt = f\"\"\"\\\n",
    "    SEARCH RESULTS:\n",
    "    ```\n",
    "    {formatted_top_results}\n",
    "    ```\n",
    "    USER'S QUESTION:\n",
    "    ```\n",
    "    {user_question}\n",
    "    ```\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the chat conversation and use GPT model for generating a response\n",
    "    messages = [{'role':'system', 'content':chatbot_system},\n",
    "                {'role':'user', 'content':prompt}]\n",
    "    \n",
    "    try:\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        completion = client.chat.completions.create(model=GPT_MODEL,\n",
    "                                             messages=messages,\n",
    "                                             temperature=0,\n",
    "                                             stream=False)\n",
    "    except Exception as e:\n",
    "        # Handle exception while communicating with ChatCompletion API\n",
    "        return f\"An error occurred with chatbot: {str(e)}\"\n",
    "        \n",
    "    # Return the chatbot response.\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b36eea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b0cf4",
   "metadata": {},
   "source": [
    "## Start Here\n",
    "After initiating environment, specify the path to pdf below and run all the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9925b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_FILE_PATH = \"2019Forester.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23899f6",
   "metadata": {},
   "source": [
    "**Converting pdf to text file.**\n",
    "> âš ï¸ **ONLY RUN ONCE.**\n",
    "> You only need to extract text once.\n",
    "\n",
    "Add `#` to the beginning of this function after extracting text from the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc31ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract_text_from_pdf(PDF_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf74411",
   "metadata": {},
   "source": [
    "**Creating embeddings from text file.**\n",
    "\n",
    "> âš ï¸ **ONLY RUN ONCE PER PDF**\n",
    "> This is a BILLED FUNCTION.\n",
    "\n",
    "`create_embeddings` function is billed, it uses OpenAI's APIs to create embeddings, use it only when required. Comment it after creating embeddings from the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da4152",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create_embeddings(EXTRACTED_TEXT_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee02280",
   "metadata": {},
   "source": [
    "**Prepare Embeddings**\n",
    "\n",
    "This reads the embeddings from the json file and stores them for chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eadb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, snippets = get_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827370bb",
   "metadata": {},
   "source": [
    "## Chatbot\n",
    "\n",
    "**To exit leave user input blank and hit enter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f5c6a8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘¤USER: How do you drain and refill the coolant?\n",
      "----------------------\n",
      "ðŸ¤– ADVISOR BOT:\n",
      "To drain and refill the coolant, follow these steps:\n",
      "\n",
      "1. Make sure the engine is completely shut off and cooled down.\n",
      "2. Locate the coolant reservoir tank on the outside of the vehicle while the engine is cool.\n",
      "3. Check the coolant level on the reservoir tank. If it is close to or lower than the \"LOW\" level mark, add coolant up to the \"FULL\" level mark. If the reservoir tank is empty, remove the radiator cap and refill coolant up to just below the filler neck.\n",
      "4. After refilling the reserve tank and the radiator, reinstall the cap and check that the rubber gaskets inside the radiator cap are in the proper position.\n",
      "5. Be careful not to spill engine coolant when adding it. If coolant touches the exhaust pipe, it may cause a bad smell, smoke, and/or a fire. If engine coolant gets on the exhaust pipe, be sure to wipe it off.\n",
      "6. If the coolant level in the reserve tank is below the \"LOW\" mark, add coolant up to the \"FULL\" mark after the engine has fully cooled down.\n",
      "7. It is recommended to have the coolant changed by your SUBARU dealer if necessary. Refer to the maintenance schedule in the \"Warranty and Maintenance Booklet\" for the coolant change interval.\n",
      "8. Do not mix SUBARU Super Coolant with any other brand or type of coolant. If it is necessary to add coolant, use only SUBARU Super Coolant.\n",
      "\n",
      "Please note that these instructions are specific to SUBARU vehicles. It is always recommended to refer to the vehicle's owner's manual for detailed instructions and safety precautions.\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# Start an infinite loop, allowing the user to ask questions\n",
    "while True:\n",
    "\n",
    "    user_question = input(\"\")\n",
    "    \n",
    "    # Prompt the user to input a question\n",
    "    print(\"ðŸ‘¤USER: \" + user_question)\n",
    "    \n",
    "    # Print a separator for readability\n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    # Check if the user entered an empty question\n",
    "    if user_question ==\"\":\n",
    "        \n",
    "        # If the user entered an empty question, exit the loop\n",
    "        break\n",
    "    else:\n",
    "        \n",
    "        # If the user entered a question, proceed to generate a response\n",
    "        print(\"ðŸ¤– ADVISOR BOT:\")\n",
    "        \n",
    "        # Call the function to generate an answer based on the user's question\n",
    "        # and print the bot's response\n",
    "        print(answer_users_question(user_question=user_question))\n",
    "        \n",
    "        # Print a separator for readability\n",
    "        print(\"----------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
